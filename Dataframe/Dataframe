Dataframe คือ Object หลักใน Apachespark โดย Dataframe คือ Dataset ที่ถูกสร้างให้อยู่ในรูปของ column ที่มีชื่อ ซึ่ง Dataframe สามารถเปรียบได้กับ spreadsheet หรือ SQL table
ส่วนประกอบสำคัญของ Dataframe ประกอบด้วย
Schema
  Schema จะใช้กำหนดชื่อ column และชนิดของ Dataframe โดยรูปแบบของข้อมูล(Data format) แต่ละแบบจะมีความหมายที่แตกต่างกันสำหรับการกำหนด schema
Rows
  Spark จะแสดงการบันทึกข้อมูลในรูปของ Row object 
Columns
  ตัว Column ใน spark มีลักษณะเดียวกับ spreadsheet และสามารถแสดงได้โดยใช้ชนิดข้อมูลพื้นฐาน เช่น string, interger หรือชนิดข้อมูลอื่น เช่น array 
Data processing
  Apache Spark ใช้ lazy evaluation ในการทำงานกับ transformation และ action ที่ใช้กำหนด Datadrame ซึ่งนี่คือแนวคิดพื้นฐานที่ใช้ทำความเข้าใจการทำงานของ data ใน Spark
  Transformation 
    ใน spark  จะส่งการประมวลผลทาง logic ในรูปของ transformation ซึ่วคือคำสั่งสำหรับ loading และจัดการข้อมูลโดยใช้ Dataframes โดยทั่วไปแล้วการ transformation จะหมายถึงการ อ่าน(reading)ข้อมูล,การรวมข้อมูล(joining),
    การ aggregation,การ type casting
  Lazy Evaluation
    Spark จะปรับแต่งข้อมูลให้เหมาะสมโดยระบุวิธีที่มีประสิทธิภาพมากที่สุดจากการ transformation ตัว Spark จะไม่ทำการ transformation จนกว่า action จะถูกเรียกให้ทำงาน โดย Spark จะรอจนกระทั่ง action ทำการคำนวณ transformation ทั้งหมดแล่วเสร็จ
  ซึ่งการทำงานแบบนี้เรียกว่า lazy evaluation หรือ lazy loading ซึ่งช่วยให้สามารถสั่งการให้ทำงานได้หลายๆอย่างในเวลาเดียวกัน
  Actions
    คือ คำสั่งที่ Spark สั่งให้คำนวณหาผลลัพธ์จากชุดของการ transformation หรือ Dataframes และ Action จะมีการคืนค่าจากการทำงาน เช่น
    ผลลัพธ์จาก console หรือ editor (display or show)
    การเก็บข้อมูล(returns Row Object) เช่น take(n),first or head
    การเขียนข้อมูลลงในแหล่งข้อมูล เช่น saveAsTable
    การ Aggregation ที่สั่งให้มีการคำนวณ เช่น count 
